import os
import hmac
import hashlib
import requests
import json
from time import gmtime, strftime
import random
from urllib.parse import urlencode, quote_plus
import re
import sys
import xml.etree.ElementTree as ET # XML íŒŒì‹±ìš©
from xml.dom import minidom # XML ì˜ˆì˜ê²Œ ì €ì¥ìš© (xmlns ì¤‘ë³µ ë°©ì§€)
from datetime import datetime

# ì¿ íŒ¡ API í‚¤ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜´ (GitHub Secretsì— ì„¤ì •!)
ACCESS_KEY = os.environ.get('COUPANG_ACCESS_KEY')
SECRET_KEY = os.environ.get('COUPANG_SECRET_KEY')

if not ACCESS_KEY or not SECRET_KEY:
    raise ValueError("COUPANG_ACCESS_KEYì™€ COUPANG_SECRET_KEYë¥¼ GitHub Secretsì— ê¼­ ì„¤ì •í•´ë¼!")

DOMAIN = "https://api-gateway.coupang.com"

# ì‚¬ì´íŠ¸ë§µ ê´€ë ¨ ì„¤ì •
SITEMAP_PATH = 'sitemap.xml'
SITE_BASE_URL = 'https://rkskqdl-a11y.github.io/' # ë„ˆì˜ ê¹ƒí—ˆë¸Œ í˜ì´ì§€ ê¸°ë³¸ URL
SITEMAP_NAMESPACE = "http://www.sitemaps.org/schemas/sitemap/0.9" # ì‚¬ì´íŠ¸ë§µ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜

# XML ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ElementTreeì— ë¯¸ë¦¬ ë“±ë¡ (ns0: ë°©ì§€)
ET.register_namespace('', SITEMAP_NAMESPACE)

# HMAC ì„œëª… ìƒì„± í•¨ìˆ˜
def generate_hmac(method, url_for_hmac, secret_key, access_key):
    path, *query = url_for_hmac.split("?")
    datetime_gmt = strftime('%y%m%d', gmtime()) + 'T' + strftime('%H%M%S', gmtime()) + 'Z'
    message = datetime_gmt + method + path + (query[0] if query else "")
    signature = hmac.new(bytes(secret_key, 'utf-8'), message.encode('utf-8'), hashlib.sha256).hexdigest()
    return f"CEA algorithm=HmacSHA256, access-key={access_key}, signed-date={datetime_gmt}, signature={signature}"

# ì¿ íŒ¡ API í˜¸ì¶œ í•¨ìˆ˜
def call_coupang_api(method, api_path, query_params=None, body=None):
    url_for_hmac = api_path
    if query_params:
        query_str = urlencode(query_params, quote_via=quote_plus)
        url_for_hmac = f"{api_path}?{query_str}"
    authorization = generate_hmac(method, url_for_hmac, SECRET_KEY, ACCESS_KEY)
    full_url = f"{DOMAIN}{url_for_hmac}"
    headers = {"Authorization": authorization, "Content-Type": "application/json"}
    if method == "GET":
        resp = requests.get(full_url, headers=headers)
    else:
        resp = requests.post(full_url, headers=headers, data=json.dumps(body))
    resp.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
    return resp.json()

# ìƒí’ˆ ê²€ìƒ‰ API í•¨ìˆ˜
def search_products(keyword, page=1, limit=10):
    api_path = "/v2/providers/affiliate_open_api/apis/openapi/products/search"
    params = {"keyword": keyword, "limit": limit, "offset": (page-1)*limit}
    return call_coupang_api("GET", api_path, params)

# HTML í˜ì´ì§€ ìƒì„± í•¨ìˆ˜ (ì„¸ë ¨ëœ ìŠ¤íƒ€ì¼, í’ë¶€í•œ ì •ë³´, ì¿ íŒ¡ ê¸€ì ì œê±°, ì´ë¯¸ì§€ ë§í¬, 'ì‹¤êµ¬ë§¤í›„ê¸°' ë²„íŠ¼ ì¶”ê°€)
def create_html(product):
    name = product.get('productName', 'ìƒí’ˆëª… ì—†ìŒ')
    url = product.get('productUrl', '#')
    img = product.get('productImage', 'https://via.placeholder.com/400x300?text=ì´ë¯¸ì§€+ì—†ìŒ') # ì´ë¯¸ì§€ ì—†ì„ ë•Œ í‘œì‹œ
    price = product.get('productPrice', 0)
    category = product.get('categoryName', 'ì •ë³´ ì—†ìŒ')
    rank = product.get('rank', 'N/A')
    
    # ë°°ì†¡ ì •ë³´ì™€ í›„ê¸° ê°œìˆ˜ëŠ” ì´ì œ HTMLì— ì§ì ‘ í‘œì‹œí•˜ì§€ ì•ŠìŒ (ìš”ì²­ ë°˜ì˜)

    # íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±° ë° ê³µë°± ëŒ€ì²´
    safe_name = re.sub(r'[\\/*?:"<>|]', '', name).replace(' ', '_')[:50].strip('_')
    if not safe_name: safe_name = f"product_{hash(name+url) % 1000000}"

    filename = f"{safe_name}.html"
    disclosure = "ì´ í¬ìŠ¤íŒ…ì€ ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ í™œë™ì˜ ì¼í™˜ìœ¼ë¡œ, ì´ì— ë”°ë¥¸ ì¼ì •ì•¡ì˜ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µí•©ë‹ˆë‹¤." # ëŒ€ê°€ì„± ë¬¸êµ¬ì—ë§Œ 'ì¿ íŒ¡'

    html_content = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>{name}</title>
<style>
  @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;700&display=swap');
  body {{
    font-family: 'Noto Sans KR', sans-serif;
    max-width: 820px; margin: auto; padding: 20px; background: #fdfdfd; color: #222;
  }}
  h1 {{
    font-weight: 700; font-size: 2.3rem; color: #333; margin-bottom: 20px; text-align: center;
  }}
  .product-img {{
    text-align: center; margin-bottom: 20px;
  }}
  .product-img img {{
    max-width: 100%; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    cursor: pointer; transition: transform 0.3s ease;
  }}
  .product-img img:hover {{
    transform: scale(1.03);
  }}
  .price {{
    font-size: 1.8rem; color: #e64e32; font-weight: 800;
    margin: 15px 0; text-align: center;
  }}
  .detail-info {{
    font-size: 1rem; line-height: 1.6; color: #555;
    border-top: 1px solid #eee; padding-top: 20px; margin-bottom: 30px;
  }}
  .detail-info p {{
    margin: 6px 0;
  }}
  .detail-info strong {{
    color: #ff5a3c;
  }}
  .button-group {{
    display: flex;
    flex-direction: column;
    gap: 15px; /* ë²„íŠ¼ ì‚¬ì´ ê°„ê²© */
    max-width: 320px;
    margin: auto; /* ì¤‘ì•™ ì •ë ¬ */
    margin-top: 25px; /* ë²„íŠ¼ ê·¸ë£¹ ìƒë‹¨ ì—¬ë°± */
  }}
  .buy-btn, .review-btn {{
    display: block;
    padding: 16px 0;
    color: #fff;
    border-radius: 14px;
    font-weight: 900;
    font-size: 1.3rem;
    text-align: center;
    text-decoration: none;
    transition: background 0.2s ease, box-shadow 0.2s ease;
    box-shadow: 0 5px 15px rgba(0,0,0,0.2); /* ê³µí†µ ê·¸ë¦¼ì */
  }}
  .buy-btn {{
    background: linear-gradient(90deg, #ff5a3c 0%, #ff7a5a 100%);
    box-shadow: 0 5px 15px rgba(255,90,60,0.6);
  }}
  .buy-btn:hover {{
    background: linear-gradient(90deg, #ff764e 0%, #ff956e 100%);
    box-shadow: 0 8px 20px rgba(255,90,60,0.8);
  }}
  .review-btn {{
    background: linear-gradient(90deg, #5c67f2 0%, #8c96ff 100%); /* ë‹¤ë¥¸ ìƒ‰ìƒ (íŒŒë€ ê³„ì—´) */
    box-shadow: 0 5px 15px rgba(92,103,242,0.6);
  }}
  .review-btn:hover {{
    background: linear-gradient(90deg, #707bf3 0%, #a0a8ff 100%);
    box-shadow: 0 8px 20px rgba(92,103,242,0.8);
  }}
  .disclosure {{
    font-size: 0.85rem;
    color: #999;
    border-top: 1px solid #eee;
    text-align: center;
    padding-top: 20px;
    margin-top: 40px;
  }}
  @media (max-width: 600px) {{
    body {{
      padding: 15px 10px;
    }}
    h1 {{
      font-size: 1.8rem;
      margin-bottom: 15px;
    }}
    .button-group {{
      max-width: none;
      width: 100%;
    }}
    .buy-btn, .review-btn {{
      padding: 14px 0;
      font-size: 1.1rem;
      border-radius: 10px;
    }}
  }}
</style>
</head>
<body>
  <h1>{name}</h1>
  <div class="product-img">
    <a href="{url}" target="_blank" rel="noopener noreferrer">
      <img src="{img}" alt="{name}">
    </a>
  </div>
  <div class="price">{price:,}ì›</div>
  <div class="detail-info">
    <p><strong>ì¹´í…Œê³ ë¦¬:</strong> {category}</p>
    <p><strong>ê²€ìƒ‰ ìˆœìœ„:</strong> {rank}ìœ„</p>
    <p>ì‹¤ì‹œê°„ ê°€ê²© ë° ìµœì‹  ì •ë³´ëŠ” ë²„íŠ¼ì„ ëˆŒëŸ¬ í™•ì¸í•˜ì„¸ìš”.</p>
  </div>
  <div class="button-group">
    <a href="{url}" class="review-btn" target="_blank" rel="nofollow noopener sponsored">ì‹¤êµ¬ë§¤í›„ê¸° ë³´ëŸ¬ê°€ê¸°</a>
    <a href="{url}" class="buy-btn" target="_blank" rel="nofollow noopener sponsored">ë°”ë¡œ êµ¬ë§¤í•˜ê¸°</a>
  </div>
  <div class="disclosure">{disclosure}</div>
</body>
</html>
"""
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(html_content)
    return filename

# --- ì‚¬ì´íŠ¸ë§µ ìë™ ì—…ë°ì´íŠ¸ ê´€ë ¨ í•¨ìˆ˜ë“¤ ---
# ET.register_namespaceëŠ” ì´ë¯¸ ìœ„ì— ì„ ì–¸í–ˆìŒ (ì „ì—­ìœ¼ë¡œ í•œ ë²ˆ)

def load_sitemap_doc():
    try:
        # íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ ëª¨ë“œ(rb)ë¡œ ì½ì–´ì„œ BOMê³¼ ê³µë°± ì²˜ë¦¬
        with open(SITEMAP_PATH, 'rb') as f:
            raw_xml_content = f.read()
        
        # BOM(Byte Order Mark)ê³¼ ë§¨ ì• ê³µë°± ì œê±° í›„ UTF-8ë¡œ ë””ì½”ë”©
        # lstrip(b'\xef\xbb\xbf')ëŠ” UTF-8 BOMì„ ì œê±°. strip()ì€ ë§¨ ì•ë’¤ ê³µë°± ì œê±°.
        xml_string = raw_xml_content.lstrip(b'\xef\xbb\xbf').strip().decode('utf-8')

        # ë¹ˆ ë¬¸ìì—´ì´ë©´ ìƒˆë¡œìš´ XML ë¬¸ì„œë¡œ ì²˜ë¦¬ (íŒŒì¼ì´ ë¹„ì—ˆì„ ë•Œ)
        if not xml_string:
            raise ValueError("Sitemap file is empty or corrupted.")

        dom = minidom.parseString(xml_string)
        
        # root elementê°€ urlsetì´ê³  ì˜¬ë°”ë¥¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì¸ì§€ í™•ì¸
        if dom.documentElement.tagName != 'urlset' or \
           dom.documentElement.getAttribute('xmlns') != SITEMAP_NAMESPACE:
            raise ValueError("Sitemap root element or namespace is invalid.")
            
    except (FileNotFoundError, ValueError, ET.ParseError):
        # íŒŒì¼ ì—†ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ ìƒˆë¡œ ë¬¸ì„œ ìƒì„±
        dom = minidom.Document()
        urlset = dom.createElement('urlset')
        urlset.setAttribute('xmlns', SITEMAP_NAMESPACE) # xmlns ì†ì„±ì„ ì—¬ê¸°ì„œë§Œ ë”±! ì„¤ì •
        dom.appendChild(urlset)
    return dom
def url_exists_in_sitemap_doc(dom_doc, target_url):
    url_elements = dom_doc.getElementsByTagName('url')
    for url_elem in url_elements:
        loc_elem = url_elem.getElementsByTagName('loc')
        if loc_elem and loc_elem[0].firstChild and loc_elem[0].firstChild.nodeValue == target_url:
            return True
    return False

def add_url_to_sitemap_doc(dom_doc, filename):
    full_url = SITE_BASE_URL + filename
    
    if url_exists_in_sitemap_doc(dom_doc, full_url):
        return False  # ì´ë¯¸ ìˆìœ¼ë©´ ì¶”ê°€ ì•ˆ í•¨

    urlset_elem = dom_doc.getElementsByTagName('urlset')[0]
    
    url_elem = dom_doc.createElement('url')
    
    loc = dom_doc.createElement('loc')
    loc.appendChild(dom_doc.createTextNode(full_url))
    url_elem.appendChild(loc)
    
    lastmod = dom_doc.createElement('lastmod')
    lastmod.appendChild(dom_doc.createTextNode(datetime.now().strftime('%Y-%m-%d')))
    url_elem.appendChild(lastmod)
    
    changefreq = dom_doc.createElement('changefreq')
    changefreq.appendChild(dom_doc.createTextNode('daily'))
    url_elem.appendChild(changefreq)
    
    priority = dom_doc.createElement('priority')
    priority.appendChild(dom_doc.createTextNode('0.8'))
    url_elem.appendChild(priority)
    
    urlset_elem.appendChild(url_elem)
    
    return True

def save_sitemap_doc(dom_doc):
    # toprettyxml ì‚¬ìš©í•´ì„œ ê¹”ë”í•˜ê²Œ ë“¤ì—¬ì“°ê¸°í•˜ê³ , encodingì€ ë‚˜ì¤‘ì— ìˆ˜ë™ ì²˜ë¦¬
    pretty_xml_as_bytes = dom_doc.toprettyxml(indent="  ", encoding="utf-8")
    
    # ë°”ì´íŠ¸ ìŠ¤íŠ¸ë§ì„ UTF-8ë¡œ ë””ì½”ë”© í›„ ì•ë’¤ ê³µë°± ì œê±° ë° íŒŒì¼ì— ì“°ê¸°
    # BOMì„ ìˆ˜ë™ìœ¼ë¡œ ì œê±°í•´ì¤˜ì•¼ í•œë‹¤ë©´ (b'\xef\xbb\xbf') ì´ëŸ° ì‹ìœ¼ë¡œ í•´ì•¼ í•˜ì§€ë§Œ
    # toprettyxmlì´ utf-8ë¡œ ì¸ì½”ë”©í•œ ê²°ê³¼ëŠ” ë³´í†µ BOMì„ í¬í•¨í•˜ì§€ ì•ŠìŒ
    # ê·¸ë˜ë„ í˜¹ì‹œ ëª¨ë¥´ë‹ˆ lstrip()ìœ¼ë¡œ ë¹ˆ ê³µê°„ë§Œ ì œê±°
    pretty_xml_as_string = pretty_xml_as_bytes.decode('utf-8').lstrip() # ë§¨ ì• ê³µë°± ì œê±°

    with open(SITEMAP_PATH, 'w', encoding='utf-8') as f:
        f.write(pretty_xml_as_string)

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
if __name__ == "__main__":
    SEARCH_KEYWORDS_LIST = [ # ë„¤ê°€ ì¤€ ê¸¸ê³  ê¸´ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸!
        "ë…¸íŠ¸ë¶", "ìº í•‘ìš©í’ˆ", "ì•„ì´í°15", "ë¬´ì„  ì´ì–´í°", "ê²Œì´ë° ë§ˆìš°ìŠ¤",
        "ì—ì–´í”„ë¼ì´ì–´", "ë¡œë´‡ì²­ì†Œê¸°", "ìº¡ìŠì»¤í”¼ë¨¸ì‹ ", "ì „ê¸° ì£¼ì „ì", "í† ìŠ¤í„°ê¸°",
        "ë¯¹ì„œê¸°", "ì œìŠµê¸°", "ê°€ìŠµê¸°", "ì„ í’ê¸°", "ì—ì–´ì»¨", "ì˜¨ìˆ˜ë§¤íŠ¸",
        "ë¸”ë£¨íˆ¬ìŠ¤ ìŠ¤í”¼ì»¤", "íƒœë¸”ë¦¿", "ìŠ¤ë§ˆíŠ¸ì›Œì¹˜", "ì™¸ì¥í•˜ë“œ", "USB ë©”ëª¨ë¦¬",
        "í•¸ë“œí° ì¼€ì´ìŠ¤", "ë¬´ì„  ì¶©ì „ê¸°", "ì°¨ëŸ‰ìš© ê±°ì¹˜ëŒ€", "ë¸”ë™ë°•ìŠ¤", "ë„¤ë¹„ê²Œì´ì…˜",
        "ê°€ì •ìš© ë¹”í”„ë¡œì í„°", "ì‚¬ìš´ë“œë°”", "TV ìŠ¤íƒ ë“œ", "ëª¨ë‹ˆí„°ì•”", "í‚¤ë³´ë“œ", "ë§ˆìš°ìŠ¤",
        "ê²Œì´ë° í—¤ë“œì…‹", "ì›¹ìº ", "ì½˜ë´ì„œ ë§ˆì´í¬", "LED ìŠ¤íƒ ë“œ", "ì˜ì", "ì±…ìƒ",
        "ì„ ë°˜", "ìˆ˜ë‚©í•¨", "ì»¤íŠ¼", "ëŸ¬ê·¸", "ì¹¨êµ¬ì„¸íŠ¸", "ë² ê°œ", "ì´ë¶ˆ", "ë§¤íŠ¸ë¦¬ìŠ¤ ì»¤ë²„",
        "ìš•ì‹¤ ìš©í’ˆ", "ì£¼ë°© ìš©í’ˆ", "í”„ë¼ì´íŒ¬", "ëƒ„ë¹„", "ë„ë§ˆ", "ì¹¼ ì„¸íŠ¸", "ì‹ê¸°ê±´ì¡°ëŒ€",
        "ì„¸íƒì„¸ì œ", "ì„¬ìœ ìœ ì—°ì œ", "ì²­ì†Œê¸°", "ë¬¼ê±¸ë ˆ ì²­ì†Œê¸°", "ìŠ¤íŒ€ë‹¤ë¦¬ë¯¸", "ë“œë¼ì´ê¸°",
        "ê³ ë°ê¸°", "ì „ë™ ì¹«ì†”", "êµ¬ê°•ì„¸ì •ê¸°", "ì˜ì–‘ì œ", "ë¹„íƒ€ë¯¼", "ìœ ì‚°ê· ", "ì½œë¼ê²",
        "ë‹¨ë°±ì§ˆ ë³´ì¶©ì œ", "ìš´ë™ë³µ", "ìš”ê°€ë§¤íŠ¸", "ë¤ë²¨", "ìì „ê±°", "ëŸ°ë‹ë¨¸ì‹ ",
        "ê³¨í”„ì±„", "ë‚šì‹¯ëŒ€", "ë“œë¡ ", "ì•¡ì…˜ìº ", "ë¯¸ëŸ¬ë¦¬ìŠ¤ ì¹´ë©”ë¼", "ë Œì¦ˆ", "ì‚¼ê°ëŒ€",
        "ë°±íŒ©", "ìºë¦¬ì–´", "ì—¬í–‰ìš© íŒŒìš°ì¹˜", "ëª©ë² ê°œ", "ë³´ì¡°ë°°í„°ë¦¬", "ë“±ì‚°í™”",
        "ìš´ë™í™”", "ìŠ¬ë¦¬í¼", "ìƒŒë“¤", "ì„ ê¸€ë¼ìŠ¤", "ëª¨ì", "ì¥ê°‘", "ì–‘ë§", "ì†ì˜·",
        "ì²­ë°”ì§€", "í‹°ì…”ì¸ ", "ê°€ë””ê±´", "ìì¼“", "ì½”íŠ¸", "ì›í”¼ìŠ¤", "ìŠ¤ì»¤íŠ¸", "ë°”ì§€",
        "êµ¬ë‘", "ì›Œì»¤", "ë¡œí¼", "í–¥ìˆ˜", "í™”ì¥í’ˆ ì„¸íŠ¸", "ìˆ˜ë¶„ í¬ë¦¼", "ì„ í¬ë¦¼",
        "ìƒ´í‘¸", "ë¦°ìŠ¤", "ë°”ë””ì›Œì‹œ", "í•¸ë“œí¬ë¦¼", "ë§ˆìŠ¤í¬íŒ©", "ë„¤ì¼", "í—¤ì–´ ì—ì„¼ìŠ¤",
        "ê³µê¸°ì²­ì •ê¸° í•„í„°", "ì •ìˆ˜ê¸° í•„í„°", "ì„¸íƒê¸° ì²­ì†Œ ì„¸ì œ", "ì„¸ë©´ëŒ€ ì²­ì†Œ ì„¸ì œ",
        "ìë™ì°¨ ì™€ì´í¼", "ì—ì–´ í•„í„°", "ì—”ì§„ ì˜¤ì¼", "íƒ€ì´ì–´ ê´‘íƒì œ", "ì„¸ì°¨ ìš©í’ˆ",
        "ì¥ë‚œê°", "ì¸í˜•", "ë¸”ë¡", "í¼ì¦", "ë³´ë“œê²Œì„", "ìœ ëª¨ì°¨", "ì¹´ì‹œíŠ¸", "ì•„ê¸°ë ",
        "ë¶„ìœ ", "ê¸°ì €ê·€", "ë¬¼í‹°ìŠˆ", "ì –ë³‘", "í„±ë°›ì´", "ì˜¨ë„ê³„", "ì²´ì˜¨ê³„",
        "ê°•ì•„ì§€ ì‚¬ë£Œ", "ê³ ì–‘ì´ ì‚¬ë£Œ", "ë°°ë³€ íŒ¨ë“œ", "ê³ ì–‘ì´ ëª¨ë˜", "ìº£íƒ€ì›Œ", "ê°•ì•„ì§€ ì§‘",
        "ì±…", "ì†Œì„¤", "ì—ì„¸ì´", "ìê¸°ê³„ë°œì„œ", "ì•„ë™ ë„ì„œ", "ë§Œí™”ì±…", "ì¡ì§€",
        "ì—°í•„", "ë³¼íœ", "ë…¸íŠ¸", "ë‹¤ì´ì–´ë¦¬", "í˜•ê´‘íœ", "ì§€ìš°ê°œ", "íŒŒì¼", "í´ë¦½"
    ]
    API_CALL_LIMIT_PER_PAGE = 10 # í•œ ë²ˆì˜ API í˜¸ì¶œë‹¹ ê°€ì ¸ì˜¬ ìƒí’ˆ ìµœëŒ€ ê°œìˆ˜
    TOTAL_PRODUCTS_TO_GENERATE = 30 # ìµœì¢… ëª©í‘œ: ì´ ìƒì„±í•  HTML íŒŒì¼ ê°œìˆ˜
    MAX_PAGES_PER_KEYWORD = 3 # í•˜ë‚˜ì˜ í‚¤ì›Œë“œë‹¹ ìµœëŒ€ ê²€ìƒ‰í•  í˜ì´ì§€ ìˆ˜ (30ê°œ ì±„ìš¸ë•Œê¹Œì§€)
    
    all_products_to_generate = [] # ìˆ˜ì§‘ëœ ëª¨ë“  ìƒí’ˆì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    keywords_attempted_set = set() # ì´ë¯¸ ì‹œë„í•œ í‚¤ì›Œë“œë¥¼ ì €ì¥í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
    
    generated_html_filenames = [] # ìƒˆë¡œ ìƒì„±ëœ HTML íŒŒì¼ëª…ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    # ëª©í‘œ ê°œìˆ˜ë§Œí¼ ìƒí’ˆì„ ëª¨ì„ ë•Œê¹Œì§€ ë°˜ë³µ
    while len(all_products_to_generate) < TOTAL_PRODUCTS_TO_GENERATE and \
          len(keywords_attempted_set) < len(SEARCH_KEYWORDS_LIST) * MAX_PAGES_PER_KEYWORD: # ë¬´í•œ ë£¨í”„ ë°©ì§€ìš© ì•ˆì „ ì¥ì¹˜
        
        selected_keyword = random.choice(SEARCH_KEYWORDS_LIST)
        if selected_keyword in keywords_attempted_set: # ì´ë¯¸ ì‹œë„í•œ í‚¤ì›Œë“œë©´ ê±´ë„ˆë›°ê³  ë‹¤ìŒ í‚¤ì›Œë“œ ì„ íƒ
            continue
        
        print(f"\nëœë¤ í‚¤ì›Œë“œ ì„ íƒ: '{selected_keyword}'")
        keywords_attempted_set.add(selected_keyword) # ì‹œë„í•œ í‚¤ì›Œë“œ ì„¸íŠ¸ì— ì¶”ê°€

        # ì„ íƒëœ í‚¤ì›Œë“œë¡œ ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ ê²€ìƒ‰í•˜ì—¬ ìƒí’ˆ ìˆ˜ì§‘
        for page_num in range(1, MAX_PAGES_PER_KEYWORD + 1):
            if len(all_products_to_generate) >= TOTAL_PRODUCTS_TO_GENERATE:
                break # ì´ë¯¸ ëª©í‘œ ê°œìˆ˜ë¥¼ ì±„ì› ìœ¼ë©´ í‚¤ì›Œë“œ/í˜ì´ì§€ ë£¨í”„ ì¤‘ë‹¨
            
            print(f"'{selected_keyword}' ìƒí’ˆ ê²€ìƒ‰ ì‹œë„ (í˜ì´ì§€ {page_num})...")
            
            try:
                search_results = search_products(selected_keyword, page=page_num, limit=API_CALL_LIMIT_PER_PAGE)
                
                products_on_current_page = search_results.get('data', {}).get('productData', [])
                
                if not products_on_current_page:
                    print(f"'{selected_keyword}' í‚¤ì›Œë“œ (í˜ì´ì§€ {page_num})ì— ë” ì´ìƒ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ í‚¤ì›Œë“œë¡œ ì´ë™.")
                    break # í˜„ì¬ í‚¤ì›Œë“œì— ë” ì´ìƒ ìƒí’ˆì´ ì—†ìœ¼ë©´ ë‹¤ìŒ í‚¤ì›Œë“œë¡œ
                
                for product_item in products_on_current_page:
                    if len(all_products_to_generate) < TOTAL_PRODUCTS_TO_GENERATE:
                        all_products_to_generate.append(product_item)
                    else:
                        break # ëª©í‘œ ê°œìˆ˜ë¥¼ ì±„ì› ìœ¼ë©´ ìƒí’ˆ ì¶”ê°€ ì¤‘ë‹¨
                        
                if len(products_on_current_page) < API_CALL_LIMIT_PER_PAGE:
                    # í˜„ì¬ í˜ì´ì§€ ìƒí’ˆ ìˆ˜ê°€ ìš”ì²­ limitë³´ë‹¤ ì ìœ¼ë©´, ì´ í‚¤ì›Œë“œì— ë” ì´ìƒ ìƒí’ˆì´ ì—†ë‹¤ê³  íŒë‹¨
                    break

            except requests.exceptions.HTTPError as http_err:
                print(f"HTTP ì˜¤ë¥˜ ({selected_keyword}, í˜ì´ì§€ {page_num}): {http_err.response.status_code} - {http_err.response.text}", file=sys.stderr)
                break # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì´ í‚¤ì›Œë“œëŠ” í¬ê¸°
            except Exception as e:
                print(f"API í˜¸ì¶œ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ({selected_keyword}, í˜ì´ì§€ {page_num}): {e}", file=sys.stderr)
                break # ë‹¤ë¥¸ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì´ í‚¤ì›Œë“œëŠ” í¬ê¸°
        
        if len(all_products_to_generate) >= TOTAL_PRODUCTS_TO_GENERATE:
            print(f"ìµœì¢… ëª©í‘œ ìƒí’ˆ ê°œìˆ˜({TOTAL_PRODUCTS_TO_GENERATE}ê°œ) ë‹¬ì„±!")
            break # ì „ì²´ ëª©í‘œ ë‹¬ì„± ì‹œ ëª¨ë“  ë£¨í”„ ì¢…ë£Œ

    # ìƒí’ˆ ìˆ˜ì§‘ ê²°ê³¼ ì²˜ë¦¬
    if not all_products_to_generate:
        print("ìµœëŒ€ ì‹œë„ í›„ì—ë„ ìƒí’ˆ ë°ì´í„°ë¥¼ í•˜ë‚˜ë„ í™•ë³´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ, API í‚¤, ë„¤íŠ¸ì›Œí¬ ìƒíƒœ ë“±ì„ í™•ì¸í•˜ì„¸ìš”.", file=sys.stderr)
        sys.exit(1) # ìƒí’ˆì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ

    print(f"\n--- ì´ {len(all_products_to_generate)}ê°œ ìƒí’ˆìœ¼ë¡œ HTML íŒŒì¼ ìƒì„± ë° ì‚¬ì´íŠ¸ë§µ ì—…ë°ì´íŠ¸ ì¤‘ ---")
    generated_html_files_count = 0
    for product_data in all_products_to_generate:
        try:
            created_filename = create_html(product_data)
            print(f"-> '{created_filename}' ìƒì„± ì™„ë£Œ")
            generated_html_filenames.append(created_filename) # ìƒì„±ëœ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            generated_html_files_count += 1
        except Exception as e:
            print(f"HTML íŒŒì¼ ìƒì„± ì‹¤íŒ¨ (ìƒí’ˆ: {product_data.get('productName', 'ë¶ˆëª…')}) : {e}", file=sys.stderr)

    # --- ì‚¬ì´íŠ¸ë§µ ì—…ë°ì´íŠ¸ ì‹¤í–‰ ---
    sitemap_dom = load_sitemap_doc() # ElementTree ëŒ€ì‹  minidom Document ê°ì²´ë¡œ ë¶ˆëŸ¬ì˜´
    sitemap_added_count = 0
    for fname in generated_html_filenames:
        if add_url_to_sitemap_doc(sitemap_dom, fname): # minidom í•¨ìˆ˜ ì‚¬ìš©
            sitemap_added_count += 1
    save_sitemap_doc(sitemap_dom) # minidom í•¨ìˆ˜ ì‚¬ìš©
    print(f"\n[ì‚¬ì´íŠ¸ë§µ] ìƒˆë¡œ ì¶”ê°€ëœ URL {sitemap_added_count}ê°œ ë°˜ì˜ ì™„ë£Œ! (íŒŒì¼: {SITEMAP_PATH})")

    print(f"\nì´ {generated_html_files_count}ê°œì˜ HTML íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ì´ì œ GitHub Actions ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•˜ì—¬ ì›¹ì‚¬ì´íŠ¸ì— ë°˜ì˜í•˜ì„¸ìš”! ğŸ‰ (sitemap.xmlë„ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ë©ë‹ˆë‹¤!)")
